# Weather Prediction

This repository contains a weather prediction project utilizing various machine learning models. The models implemented include Decision Tree, K-Nearest Neighbors (KNN), Multi-Layer Perceptron Neural Network (MLP NN), Random Forest, LightGBM, CatBoost, and XGBoost. The project aims to predict weather conditions based on historical data.

# Overview

The goal of this project is to leverage various machine learning algorithms to predict weather conditions such as temperature, humidity, and precipitation. By comparing the performance of different models, we aim to identify the most effective approach for accurate weather prediction.

# Models Used

The following models have been implemented in this project:

- Decision Tree: A simple and interpretable model that splits data based on feature values.
- K-Nearest Neighbors (KNN): A non-parametric model that predicts the target based on the closest data points.
- Multi-Layer Perceptron Neural Network (MLP NN): A feedforward neural network with multiple layers for complex pattern recognition.
- Random Forest: An ensemble model that combines multiple decision trees to improve accuracy and reduce overfitting.
- LightGBM: A gradient boosting framework that uses tree-based learning algorithms, optimized for performance and speed.
- CatBoost: A gradient boosting algorithm that handles categorical features automatically, reducing the need for preprocessing.
- XGBoost: An optimized gradient boosting algorithm known for its efficiency and predictive power.

# Dataset

The dataset used to train this model can be found on kaggle [here](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package). 

# Results

After training, model performance will be compared based on metrics such as accuracy, precision, recall, and F1 score. These results will help determine the most effective model for weather prediction. Various graphs were also produced to visually represent the model results, such as ROC curves and accuracy matrices.
